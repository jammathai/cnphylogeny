{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b630fb8c",
   "metadata": {},
   "source": [
    "# Performance Optimization\n",
    "\n",
    "Now that the Gibbs sampling algorithm and analysis function appear to be working correctly, I'd like to optimize. There are certain easy optimizations that will probably save at least a little time.\n",
    "\n",
    "This is my starting point (running `time build/cnphylogeny data/PTX005/input`):\n",
    "\n",
    "```\n",
    "real    0m53.035s\n",
    "user    0m52.956s\n",
    "sys     0m0.002s\n",
    "```\n",
    "\n",
    "Note that I've already applied compiler optimizations, so any speedup from here will be my own doing.\n",
    "\n",
    "## Don't Normalize Probability Distributions\n",
    "\n",
    "Currently, I normalize probabilities, like this:\n",
    "\n",
    "```\n",
    "double total = 0;\n",
    "for (int i = 0; i <= max_copy_num; i++) total += probs[i];\n",
    "for (int i = 0; i <= max_copy_num; i++) probs[i] /= total;\n",
    "```\n",
    "\n",
    "This wastes time and modifies `probs`, which is a potential bug waiting to happen. First step is to make the sampling algorithm account for `total` instead of doing a bunch of divisions.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
